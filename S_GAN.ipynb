{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDXck-2aGkEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torch # framework\n",
        "!apt-get install x11-utils # visualization\n",
        "!pip install stable-baselines # multiple environment\n",
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1 # visualization\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1 # visualization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ7QF4YbN1Pl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') \n",
        "%cd /content/drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCY2rWEiOqDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.functional import binary_cross_entropy_with_logits, mse_loss\n",
        "from critic import BasicCritic\n",
        "from decoder import BasicDecoder\n",
        "from encoder import BasicEncoder\n",
        "from torchvision import datasets, transforms\n",
        "from IPython.display import clear_output\n",
        "import torchvision\n",
        "from torch.optim import Adam\n",
        "import pytorch_ssim\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import os\n",
        "import gc\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVLWLMetCrGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot(name, train_epoch, values, save):\n",
        "    clear_output(wait=True)\n",
        "    plt.close('all')\n",
        "    fig = plt.figure()\n",
        "    fig = plt.ion()\n",
        "    fig = plt.subplot(1, 1, 1)\n",
        "    fig = plt.title('epoch: %s -> %s: %s' % (train_epoch, name, values[-1]))\n",
        "    fig = plt.ylabel(name)\n",
        "    fig = plt.xlabel('epoch')\n",
        "    fig = plt.plot(values)\n",
        "    fig = plt.grid()\n",
        "    get_fig = plt.gcf()\n",
        "    fig = plt.draw()  # draw the plot\n",
        "    fig = plt.pause(1)  # show it for 1 second\n",
        "    if save:\n",
        "        now = datetime.datetime.now()\n",
        "        get_fig.savefig('results/plots/%s_%d_%d_%s.png' %\n",
        "                        (name, train_epoch, values[-1], now.strftime(\"%Y-%m-%d_%H:%M:%S\")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF4iLYgOOm0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    data_dir = 'div2k'\n",
        "    epochs = 5\n",
        "    data_depth = 2\n",
        "    hidden_size = 32\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    METRIC_FIELDS = [\n",
        "        'val.encoder_mse',\n",
        "        'val.decoder_loss',\n",
        "        'val.decoder_acc',\n",
        "        'val.cover_score',\n",
        "        'val.generated_score',\n",
        "        'val.ssim',\n",
        "        'val.psnr',\n",
        "        'val.bpp',\n",
        "        'train.encoder_mse',\n",
        "        'train.decoder_loss',\n",
        "        'train.decoder_acc',\n",
        "        'train.cover_score',\n",
        "        'train.generated_score',\n",
        "    ]\n",
        "\n",
        "    mu = [.5, .5, .5]\n",
        "    sigma = [.5, .5, .5]\n",
        "\n",
        "    transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                    transforms.RandomCrop(\n",
        "                                        360, pad_if_needed=True),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mu, sigma)])\n",
        "\n",
        "    train_set = datasets.ImageFolder(os.path.join(\n",
        "        data_dir, \"train/\"), transform=transform)\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_set, batch_size=4, shuffle=True)\n",
        "\n",
        "    valid_set = datasets.ImageFolder(os.path.join(\n",
        "        data_dir, \"val/\"), transform=transform)\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        valid_set, batch_size=4, shuffle=False)\n",
        "\n",
        "    encoder = BasicEncoder(data_depth, hidden_size)\n",
        "    decoder = BasicDecoder(data_depth, hidden_size)\n",
        "    critic = BasicCritic(hidden_size)\n",
        "    cr_optimizer = Adam(critic.parameters(), lr=1e-4)\n",
        "    # Why add encoder parameters too?\n",
        "    en_de_optimizer = Adam(list(decoder.parameters()) +\n",
        "                           list(encoder.parameters()), lr=1e-4)\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        metrics = {field: list() for field in METRIC_FIELDS}\n",
        "        for cover, _ in tqdm(train_loader):\n",
        "            gc.collect()\n",
        "            cover = cover.to(device)\n",
        "            N, _, H, W = cover.size()\n",
        "            # sampled from the discrete uniform distribution over 0 to 2\n",
        "            payload = torch.zeros((N, data_depth, H, W),\n",
        "                                  device=device).random_(0, 2)\n",
        "            generated = encoder.forward(cover, payload)\n",
        "            cover_score = torch.mean(critic.forward(cover))\n",
        "            generated_score = torch.mean(critic.forward(generated))\n",
        "\n",
        "            cr_optimizer.zero_grad()\n",
        "            (cover_score - generated_score).backward(retain_graph=False)\n",
        "            cr_optimizer.step()\n",
        "\n",
        "            for p in critic.parameters():\n",
        "                p.data.clamp_(-0.1, 0.1)\n",
        "            metrics['train.cover_score'].append(cover_score.item())\n",
        "            metrics['train.generated_score'].append(generated_score.item())\n",
        "\n",
        "        for cover, _ in tqdm(train_loader):\n",
        "            gc.collect()\n",
        "            cover = cover.to(device)\n",
        "            N, _, H, W = cover.size()\n",
        "            # sampled from the discrete uniform distribution over 0 to 2\n",
        "            payload = torch.zeros((N, data_depth, H, W),\n",
        "                                  device=device).random_(0, 2)\n",
        "            generated = encoder.forward(cover, payload)\n",
        "            decoded = decoder.forward(generated)\n",
        "\n",
        "            encoder_mse = mse_loss(generated, cover)\n",
        "            decoder_loss = binary_cross_entropy_with_logits(decoded, payload)\n",
        "            decoder_acc = (decoded >= 0.0).eq(\n",
        "                payload >= 0.5).sum().float() / payload.numel()\n",
        "            generated_score = torch.mean(critic.forward(generated))\n",
        "\n",
        "            en_de_optimizer.zero_grad()\n",
        "            (100.0 * encoder_mse + decoder_loss +\n",
        "             generated_score).backward()  # Why 100?\n",
        "            en_de_optimizer.step()\n",
        "\n",
        "            metrics['train.encoder_mse'].append(encoder_mse.item())\n",
        "            metrics['train.decoder_loss'].append(decoder_loss.item())\n",
        "            metrics['train.decoder_acc'].append(decoder_acc.item())\n",
        "\n",
        "        for cover, _ in tqdm(valid_loader):\n",
        "            gc.collect()\n",
        "            cover = cover.to(device)\n",
        "            N, _, H, W = cover.size()\n",
        "            # sampled from the discrete uniform distribution over 0 to 2\n",
        "            payload = torch.zeros((N, data_depth, H, W),\n",
        "                                  device=device).random_(0, 2)\n",
        "            generated = encoder.forward(cover, payload)\n",
        "            decoded = decoder.forward(generated)\n",
        "\n",
        "            encoder_mse = mse_loss(generated, cover)\n",
        "            decoder_loss = binary_cross_entropy_with_logits(decoded, payload)\n",
        "            decoder_acc = (decoded >= 0.0).eq(\n",
        "                payload >= 0.5).sum().float() / payload.numel()\n",
        "            generated_score = torch.mean(critic.forward(generated))\n",
        "            cover_score = torch.mean(critic.forward(cover))\n",
        "\n",
        "            metrics['val.encoder_mse'].append(encoder_mse.item())\n",
        "            metrics['val.decoder_loss'].append(decoder_loss.item())\n",
        "            metrics['val.decoder_acc'].append(decoder_acc.item())\n",
        "            metrics['val.cover_score'].append(cover_score.item())\n",
        "            metrics['val.generated_score'].append(generated_score.item())\n",
        "            metrics['val.ssim'].append(\n",
        "                pytorch_ssim.ssim(cover, generated).item())\n",
        "            metrics['val.psnr'].append(\n",
        "                10 * torch.log10(4 / encoder_mse).item())\n",
        "            metrics['val.bpp'].append(\n",
        "                data_depth * (2 * decoder_acc.item() - 1))\n",
        "        now = datetime.datetime.now()\n",
        "        name = \"EN_DE_%+.3f_%s.dat\" % (cover_score.item(),\n",
        "                                       now.strftime(\"%Y-%m-%d_%H:%M:%S\"))\n",
        "        fname = os.path.join('.', 'results/model', name)\n",
        "        states = {\n",
        "            'state_dict_critic': critic.state_dict(),\n",
        "            'state_dict_encoder': encoder.state_dict(),\n",
        "            'state_dict_decoder': decoder.state_dict(),\n",
        "            'en_de_optimizer': en_de_optimizer.state_dict(),\n",
        "            'cr_optimizer': cr_optimizer.state_dict(),\n",
        "            'metrics': metrics,\n",
        "            'train_epoch': ep,\n",
        "            'date': now.strftime(\"%Y-%m-%d_%H:%M:%S\"),\n",
        "        }\n",
        "        torch.save(states, fname)\n",
        "        plot('encoder_mse', ep, metrics['val.encoder_mse'], True)\n",
        "        plot('decoder_loss', ep, metrics['val.decoder_loss'], True)\n",
        "        plot('decoder_acc', ep, metrics['val.decoder_acc'], True)\n",
        "        plot('cover_score', ep, metrics['val.cover_score'], True)\n",
        "        plot('generated_score', ep, metrics['val.generated_score'], True)\n",
        "        plot('ssim', ep, metrics['val.ssim'], True)\n",
        "        plot('psnr', ep, metrics['val.psnr'], True)\n",
        "        plot('bpp', ep, metrics['val.bpp'], True)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    for func in [\n",
        "            lambda:os.mkdir(os.path.join('.', 'results')),\n",
        "            lambda: os.mkdir(os.path.join('.', 'results/model')),\n",
        "            lambda: os.mkdir(os.path.join('.', 'results/metrics')),\n",
        "            lambda: os.mkdir(os.path.join('.', 'results/plots'))]:  # create directories\n",
        "        try:\n",
        "            func()\n",
        "        except Exception as error:\n",
        "            print(error)\n",
        "            continue\n",
        "    main()\n",
        "\n",
        "\n",
        "                "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}